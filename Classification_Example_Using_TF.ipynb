{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "for root,sub,file in os.walk(\"dogs-vs-cats/train/train\"):\n",
    "    for file_name in file:\n",
    "        train.append(root+\"/\"+file_name)\n",
    "random.shuffle(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model():\n",
    "\n",
    "    Layer_1 = tf.placeholder(name=\"Input\", shape=(None,64,64,3), dtype=\"float32\")\n",
    "    \n",
    "    Layer_2 = tf.layers.conv2d(inputs=Layer_1, kernel_size=(3,3), strides=(2,2), filters=20)\n",
    "    Layer_3 = tf.layers.dropout(inputs=Layer_2, rate=0.2)\n",
    "    Layer_4 = tf.layers.conv2d(inputs=Layer_3, kernel_size=(1,1), strides=(1,1), filters=30)\n",
    "    Layer_5 = tf.nn.relu(features=Layer_4)\n",
    "    Layer_6 = tf.layers.batch_normalization(inputs=Layer_5)\n",
    "    \n",
    "    Layer_7 = tf.layers.conv2d(inputs=Layer_6, kernel_size=(3,3), strides=(2,2), filters=40)\n",
    "    Layer_8 = tf.layers.dropout(inputs=Layer_7,rate=0.2)\n",
    "    Layer_9 = tf.layers.conv2d(inputs=Layer_8, kernel_size=(1,1), strides=(1,1), filters=40)\n",
    "    Layer_10 = tf.nn.relu(features=Layer_9)\n",
    "    Layer_11 = tf.layers.batch_normalization(inputs=Layer_10)\n",
    "\n",
    "    Layer_12 = tf.layers.conv2d(inputs=Layer_11, kernel_size=(3,3), strides=(2,2), filters=50)\n",
    "    Layer_13 = tf.layers.dropout(inputs=Layer_12,rate=0.2)\n",
    "    Layer_14 = tf.layers.conv2d(inputs=Layer_13, kernel_size=(1,1), strides=(1,1), filters=50)\n",
    "    Layer_15 = tf.nn.relu(features=Layer_14)\n",
    "    Layer_16 = tf.layers.batch_normalization(inputs=Layer_15)\n",
    "    \n",
    "    Layer_17 = tf.layers.conv2d(inputs=Layer_16, kernel_size=(7,7), strides=1, filters=2)\n",
    "    Layer_18 = tf.reshape(tensor=Layer_17, shape=(-1,2))\n",
    "#     Layer_18 = tf.squeeze(Layer_17, [1,2])\n",
    "    \n",
    "    return Layer_1, Layer_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input, model_output = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for variables in tf.all_variables():\n",
    "#     print(\"Name  : \", variables.name)\n",
    "#     print(\"Shape : \", variables.shape)\n",
    "#     print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_output = tf.placeholder(shape=(None, 2), dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model_output, labels=actual_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = tf.losses.mean_squared_error(out=model_output, onehot_labels=actual_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\"cat\":[0,1], \"dog\":[1,0]}\n",
    "for i in range(10):\n",
    "    random.shuffle(train)\n",
    "    for j in range(0,len(train)-32,32):\n",
    "        image = []\n",
    "        label = []\n",
    "        for k in range(j,j+32):\n",
    "            img = cv2.imread(train[k])\n",
    "            img = img/255 - 0.5 \n",
    "            img = cv2.resize(img, (64,64))\n",
    "            img = np.array(img).astype(\"float32\")\n",
    "            image.append(img)\n",
    "            label.append(label_dict[train[k].split(\"/\")[-1].split(\".\")[0]])   \n",
    "        opt_ , loss_val = sess.run([optimizer, loss], feed_dict={model_input : image, actual_output : np.array(label).astype(\"float32\")})\n",
    "        print(loss_val)\n",
    "#         break\n",
    "#     break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
